{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02_exploratory_data_analysis\n",
        "\n",
        "## Comprehensive EDA for Biomass and Carbon Data\n",
        "\n",
        "**Objectives:**\n",
        "- Analyze spatial patterns\n",
        "- Identify correlations between variables\n",
        "- Visualize carbon distribution\n",
        "- Detect outliers and anomalies\n",
        "- Feature importance analysis\n",
        "- Interactive mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Dependencies and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium import plugins\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import scipy.stats as stats\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data from previous notebook\n",
        "try:\n",
        "    biomass_df = pd.read_csv('data/processed_biomass_csv.csv')\n",
        "    json_df = pd.read_csv('data/processed_biomass_json.csv')\n",
        "    print(\"‚úÖ Successfully loaded processed data\")\n",
        "    print(f\"Biomass data shape: {biomass_df.shape}\")\n",
        "    print(f\"JSON data shape: {json_df.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è Processed data not found. Creating sample data...\")\n",
        "    from src.data_processing.loader import EnhancedBiomassLoader\n",
        "    loader = EnhancedBiomassLoader()\n",
        "    loader.create_sample_csv()\n",
        "    loader.create_sample_json()\n",
        "    biomass_df = loader.load_csv(\"sample_biomass.csv\")\n",
        "    json_data = loader.load_json(\"sample_biomass.json\")\n",
        "    \n",
        "    # Convert JSON to DataFrame\n",
        "    biomass_readings = []\n",
        "    for reading in json_data['biomass_readings']:\n",
        "        biomass_readings.append({\n",
        "            'site_id': reading['site_id'],\n",
        "            'biomass': reading['biomass'],\n",
        "            'latitude': reading['coordinates']['lat'],\n",
        "            'longitude': reading['coordinates']['lon'],\n",
        "            'quality_flag': reading['quality_flag']\n",
        "        })\n",
        "    json_df = pd.DataFrame(biomass_readings)\n",
        "\n",
        "# Add carbon estimation (assuming biomass to carbon conversion factor)\n",
        "def biomass_to_carbon(biomass, conversion_factor=0.47):\n",
        "    \"\"\"Convert biomass to carbon stock using standard conversion factor.\"\"\"\n",
        "    return biomass * conversion_factor\n",
        "\n",
        "# Add carbon columns\n",
        "biomass_df['carbon_stock'] = biomass_to_carbon(biomass_df['biomass_value'])\n",
        "json_df['carbon_stock'] = biomass_to_carbon(json_df['biomass'])\n",
        "\n",
        "# Display basic info\n",
        "print(\"\\nüìä Biomass Data Overview:\")\n",
        "print(biomass_df.info())\n",
        "print(\"\\nüìä JSON Data Overview:\")\n",
        "print(json_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Spatial Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_spatial_distribution(df, title_suffix=\"\"):\n",
        "    \"\"\"Comprehensive spatial analysis of biomass and carbon distribution.\"\"\"\n",
        "    \n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            f'Biomass Spatial Distribution {title_suffix}',\n",
        "            f'Carbon Stock Spatial Distribution {title_suffix}',\n",
        "            'Biomass Density Heatmap',\n",
        "            'Carbon Density Heatmap'\n",
        "        ),\n",
        "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "    )\n",
        "    \n",
        "    # Scatter plots for spatial distribution\n",
        "    biomass_col = 'biomass_value' if 'biomass_value' in df.columns else 'biomass'\n",
        "    \n",
        "    # 1. Biomass spatial scatter\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['longitude'], y=df['latitude'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color=df[biomass_col],\n",
        "                colorscale='Viridis',\n",
        "                showscale=True,\n",
        "                colorbar=dict(title='Biomass')\n",
        "            ),\n",
        "            text=df[biomass_col].round(2),\n",
        "            hovertemplate='<b>Lat</b>: %{y}<br><b>Lon</b>: %{x}<br><b>Biomass</b>: %{text}<extra></extra>'\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Carbon spatial scatter\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=df['longitude'], y=df['latitude'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color=df['carbon_stock'],\n",
        "                colorscale='Plasma',\n",
        "                showscale=True,\n",
        "                colorbar=dict(title='Carbon')\n",
        "            ),\n",
        "            text=df['carbon_stock'].round(2),\n",
        "            hovertemplate='<b>Lat</b>: %{y}<br><b>Lon</b>: %{x}<br><b>Carbon</b>: %{text}<extra></extra>'\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Biomass density heatmap\n",
        "    fig.add_trace(\n",
        "        go.Densitymapbox(\n",
        "            lat=df['latitude'],\n",
        "            lon=df['longitude'],\n",
        "            z=df[biomass_col],\n",
        "            radius=20,\n",
        "            colorscale='Viridis',\n",
        "            colorbar=dict(title='Biomass Density')\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # 4. Carbon density heatmap\n",
        "    fig.add_trace(\n",
        "        go.Densitymapbox(\n",
        "            lat=df['latitude'],\n",
        "            lon=df['longitude'],\n",
        "            z=df['carbon_stock'],\n",
        "            radius=20,\n",
        "            colorscale='Plasma',\n",
        "            colorbar=dict(title='Carbon Density')\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=f\"Spatial Distribution Analysis {title_suffix}\",\n",
        "        height=800,\n",
        "        showlegend=False\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Spatial statistics\n",
        "    print(f\"\\nüìà Spatial Statistics {title_suffix}:\")\n",
        "    print(f\"Geographic Range - Lat: {df['latitude'].min():.4f} to {df['latitude'].max():.4f}\")\n",
        "    print(f\"Geographic Range - Lon: {df['longitude'].min():.4f} to {df['longitude'].max():.4f}\")\n",
        "    print(f\"Spatial Coverage: {df['latitude'].max() - df['latitude'].min():.4f}¬∞ lat √ó {df['longitude'].max() - df['longitude'].min():.4f}¬∞ lon\")\n",
        "\n",
        "# Analyze spatial distribution for both datasets\n",
        "analyze_spatial_distribution(biomass_df, \"(CSV Data)\")\n",
        "analyze_spatial_distribution(json_df, \"(JSON Data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Matrix of Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comprehensive_correlation_analysis(df, title_suffix=\"\"):\n",
        "    \"\"\"Perform detailed correlation analysis with multiple visualization methods.\"\"\"\n",
        "    \n",
        "    # Select numerical columns for correlation\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    corr_matrix = df[numerical_cols].corr()\n",
        "    \n",
        "    # Create subplots\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            f'Correlation Matrix {title_suffix}',\n",
        "            'Correlation Heatmap',\n",
        "            'Top Correlations with Biomass',\n",
        "            'Top Correlations with Carbon'\n",
        "        ),\n",
        "        specs=[[{\"type\": \"table\"}, {\"type\": \"heatmap\"}],\n",
        "               [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        "    )\n",
        "    \n",
        "    # 1. Correlation matrix table\n",
        "    fig.add_trace(\n",
        "        go.Table(\n",
        "            header=dict(values=['Variable'] + list(corr_matrix.columns)),\n",
        "            cells=dict(values=[corr_matrix.index] + [corr_matrix[col].round(3) for col in corr_matrix.columns])\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Correlation heatmap\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=corr_matrix.values,\n",
        "            x=corr_matrix.columns,\n",
        "            y=corr_matrix.index,\n",
        "            colorscale='RdBu_r',\n",
        "            zmin=-1, zmax=1,\n",
        "            colorbar=dict(title='Correlation')\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Top correlations with biomass\n",
        "    biomass_col = 'biomass_value' if 'biomass_value' in corr_matrix.index else 'biomass'\n",
        "    if biomass_col in corr_matrix.index:\n",
        "        biomass_corrs = corr_matrix[biomass_col].drop(biomass_col).sort_values(ascending=False)\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=biomass_corrs.index, y=biomass_corrs.values,\n",
        "                  marker_color='lightgreen'),\n",
        "            row=2, col=1\n",
        "        )\n",
        "    \n",
        "    # 4. Top correlations with carbon\n",
        "    if 'carbon_stock' in corr_matrix.index:\n",
        "        carbon_corrs = corr_matrix['carbon_stock'].drop('carbon_stock').sort_values(ascending=False)\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=carbon_corrs.index, y=carbon_corrs.values,\n",
        "                  marker_color='lightcoral'),\n",
        "            row=2, col=2\n",
        "        )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=f\"Comprehensive Correlation Analysis {title_suffix}\",\n",
        "        height=800\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Statistical significance of correlations\n",
        "    print(f\"\\nüîç Correlation Insights {title_suffix}:\")\n",
        "    for col1 in corr_matrix.columns:\n",
        "        for col2 in corr_matrix.columns:\n",
        "            if col1 < col2 and abs(corr_matrix.loc[col1, col2]) > 0.5:\n",
        "                print(f\"Strong correlation: {col1} ‚Üî {col2}: {corr_matrix.loc[col1, col2]:.3f}\")\n",
        "\n",
        "# Perform correlation analysis for both datasets\n",
        "comprehensive_correlation_analysis(biomass_df, \"(CSV Data)\")\n",
        "comprehensive_correlation_analysis(json_df, \"(JSON Data)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Temporal Trends Analysis (Simulated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_temporal_trends():\n",
        "    \"\"\"Analyze temporal patterns in biomass and carbon data (simulated).\"\"\"\n",
        "    \n",
        "    # Simulate temporal data (monthly trends over 2 years)\n",
        "    dates = pd.date_range('2022-01-01', '2023-12-31', freq='M')\n",
        "    n_periods = len(dates)\n",
        "    \n",
        "    # Simulate seasonal biomass patterns\n",
        "    base_biomass = 2.5\n",
        "    seasonal_pattern = np.sin(2 * np.pi * np.arange(n_periods) / 12) * 0.8  # Annual cycle\n",
        "    trend = np.arange(n_periods) * 0.05  # Slight increasing trend\n",
        "    noise = np.random.normal(0, 0.2, n_periods)\n",
        "    \n",
        "    simulated_biomass = base_biomass + seasonal_pattern + trend + noise\n",
        "    simulated_carbon = biomass_to_carbon(simulated_biomass)\n",
        "    \n",
        "    temporal_df = pd.DataFrame({\n",
        "        'date': dates,\n",
        "        'biomass': simulated_biomass,\n",
        "        'carbon_stock': simulated_carbon,\n",
        "        'month': dates.month,\n",
        "        'year': dates.year\n",
        "    })\n",
        "    \n",
        "    # Create temporal visualizations\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            'Biomass Trends Over Time',\n",
        "            'Carbon Stock Trends Over Time',\n",
        "            'Seasonal Biomass Patterns',\n",
        "            'Year-over-Year Comparison'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # 1. Biomass trends\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=temporal_df['date'], y=temporal_df['biomass'],\n",
        "                 mode='lines+markers', name='Biomass', line=dict(color='green')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Carbon trends\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=temporal_df['date'], y=temporal_df['carbon_stock'],\n",
        "                 mode='lines+markers', name='Carbon Stock', line=dict(color='blue')),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Seasonal patterns\n",
        "    monthly_avg = temporal_df.groupby('month').agg({'biomass': 'mean', 'carbon_stock': 'mean'}).reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=monthly_avg['month'], y=monthly_avg['biomass'],\n",
        "                 mode='lines+markers', name='Monthly Biomass', line=dict(color='darkgreen')),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # 4. Year-over-year comparison\n",
        "    yearly_avg = temporal_df.groupby('year').agg({'biomass': 'mean', 'carbon_stock': 'mean'}).reset_index()\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=yearly_avg['year'], y=yearly_avg['biomass'],\n",
        "              name='Yearly Avg Biomass', marker_color='lightgreen'),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=\"Temporal Trends Analysis (Simulated Data)\",\n",
        "        height=700\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Statistical analysis of trends\n",
        "    print(\"\\nüìà Temporal Analysis Insights:\")\n",
        "    print(f\"Overall biomass trend: {temporal_df['biomass'].iloc[-1] - temporal_df['biomass'].iloc[0]:.3f} change\")\n",
        "    print(f\"Seasonal amplitude: {simulated_biomass.max() - simulated_biomass.min():.3f}\")\n",
        "    print(f\"Average monthly biomass: {temporal_df['biomass'].mean():.3f} ¬± {temporal_df['biomass'].std():.3f}\")\n",
        "    \n",
        "    return temporal_df\n",
        "\n",
        "# Run temporal analysis\n",
        "temporal_data = analyze_temporal_trends()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def feature_importance_analysis(df, target_column):\n",
        "    \"\"\"Analyze feature importance for predicting biomass/carbon.\"\"\"\n",
        "    \n",
        "    # Prepare features and target\n",
        "    feature_columns = [col for col in df.columns if col not in [target_column, 'site_id', 'quality_flag', 'biomass_category'] \n",
        "                     and pd.api.types.is_numeric_dtype(df[col])]\n",
        "    \n",
        "    X = df[feature_columns].fillna(df[feature_columns].median())\n",
        "    y = df[target_column]\n",
        "    \n",
        "    # Remove constant columns\n",
        "    X = X.loc[:, X.std() > 0]\n",
        "    \n",
        "    if len(X.columns) == 0:\n",
        "        print(f\"No valid features for {target_column} analysis\")\n",
        "        return\n",
        "    \n",
        "    # Random Forest for feature importance\n",
        "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf.fit(X, y)\n",
        "    \n",
        "    # Get feature importance\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': rf.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    # Create visualization\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=(\n",
        "            f'Feature Importance for {target_column}',\n",
        "            'Cumulative Importance'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # Feature importance bars\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=importance_df['importance'], y=importance_df['feature'],\n",
        "              orientation='h', marker_color='skyblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Cumulative importance\n",
        "    cumulative_importance = importance_df['importance'].cumsum()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=cumulative_importance, y=importance_df['feature'],\n",
        "                 mode='lines+markers', line=dict(color='red', width=3)),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=f\"Feature Importance Analysis - {target_column}\",\n",
        "        height=500,\n",
        "        showlegend=False\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Print insights\n",
        "    print(f\"\\nüîç Feature Importance for {target_column}:\")\n",
        "    print(f\"Top 3 most important features:\")\n",
        "    for i, row in importance_df.head(3).iterrows():\n",
        "        print(f\"  {row['feature']}: {row['importance']:.3f}\")\n",
        "    \n",
        "    print(f\"\\nFeatures explaining 80% of variance: {len(cumulative_importance[cumulative_importance <= 0.8])}\")\n",
        "    \n",
        "    return importance_df\n",
        "\n",
        "# Analyze feature importance for both targets\n",
        "print(\"=\"*60)\n",
        "target_col = 'biomass_value' if 'biomass_value' in biomass_df.columns else 'biomass'\n",
        "biomass_importance = feature_importance_analysis(biomass_df, target_col)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "carbon_importance = feature_importance_analysis(biomass_df, 'carbon_stock')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Maps with Folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_interactive_maps(df, map_title=\"Biomass Distribution\"):\n",
        "    \"\"\"Create interactive Folium maps for spatial analysis.\"\"\"\n",
        "    \n",
        "    biomass_col = 'biomass_value' if 'biomass_value' in df.columns else 'biomass'\n",
        "    \n",
        "    # Calculate center of the data\n",
        "    center_lat = df['latitude'].mean()\n",
        "    center_lon = df['longitude'].mean()\n",
        "    \n",
        "    # Create base map\n",
        "    m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n",
        "    \n",
        "    # Add biomass points\n",
        "    for idx, row in df.iterrows():\n",
        "        # Determine color based on biomass value\n",
        "        biomass_val = row[biomass_col]\n",
        "        if biomass_val < 1.5:\n",
        "            color = 'lightgray'\n",
        "        elif biomass_val < 2.5:\n",
        "            color = 'lightgreen'\n",
        "        elif biomass_val < 3.5:\n",
        "            color = 'green'\n",
        "        else:\n",
        "            color = 'darkgreen'\n",
        "        \n",
        "        # Create popup text\n",
        "        popup_text = f\"\"\"\n",
        "        <b>Location Info</b><br>\n",
        "        Biomass: {biomass_val:.2f}<br>\n",
        "        Carbon: {row['carbon_stock']:.2f}<br>\n",
        "        Lat: {row['latitude']:.4f}<br>\n",
        "        Lon: {row['longitude']:.4f}<br>\n",
        "        \"\"\"\n",
        "        \n",
        "        if 'vegetation_type' in row:\n",
        "            popup_text += f\"Vegetation: {row['vegetation_type']}<br>\"\n",
        "        \n",
        "        # Add marker\n",
        "        folium.CircleMarker(\n",
        "            location=[row['latitude'], row['longitude']],\n",
        "            radius=8,\n",
        "            popup=folium.Popup(popup_text, max_width=300),\n",
        "            color=color,\n",
        "            fillColor=color,\n",
        "            fillOpacity=0.7,\n",
        "            weight=1\n",
        "        ).add_to(m)\n",
        "    \n",
        "    # Add heatmap\n",
        "    heat_data = [[row['latitude'], row['longitude'], row[biomass_col]] for idx, row in df.iterrows()]\n",
        "    plugins.HeatMap(heat_data, name='Biomass Heatmap', min_opacity=0.3, max_zoom=18).add_to(m)\n",
        "    \n",
        "    # Add layer control\n",
        "    folium.LayerControl().add_to(m)\n",
        "    \n",
        "    # Add title\n",
        "    title_html = f'''\n",
        "             <h3 align=\"center\" style=\"font-size:20px\"><b>{map_title}</b></h3>\n",
        "             '''\n",
        "    m.get_root().html.add_child(folium.Element(title_html))\n",
        "    \n",
        "    return m\n",
        "\n",
        "# Create interactive maps\n",
        "print(\"üåç Creating Interactive Maps...\")\n",
        "\n",
        "map1 = create_interactive_maps(biomass_df, \"Biomass Distribution - CSV Data\")\n",
        "print(\"‚úÖ CSV Data Map Created\")\n",
        "\n",
        "map2 = create_interactive_maps(json_df, \"Biomass Distribution - JSON Data\")\n",
        "print(\"‚úÖ JSON Data Map Created\")\n",
        "\n",
        "# Display maps\n",
        "print(\"\\nüìã Map Legend:\")\n",
        "print(\"üî¥ Red points: High biomass (> 3.5)\")\n",
        "print(\"üü¢ Green points: Medium biomass (2.5-3.5)\")\n",
        "print(\"üü° Yellow points: Low biomass (1.5-2.5)\")\n",
        "print(\"‚ö™ Gray points: Very low biomass (< 1.5)\")\n",
        "\n",
        "# Save maps\n",
        "map1.save('outputs/biomass_map_csv.html')\n",
        "map2.save('outputs/biomass_map_json.html')\n",
        "print(\"\\nüíæ Maps saved to 'outputs/' directory\")\n",
        "\n",
        "# Display one map in notebook\n",
        "display(map1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Outlier and Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_anomalies(df):\n",
        "    \"\"\"Comprehensive outlier and anomaly detection.\"\"\"\n",
        "    \n",
        "    biomass_col = 'biomass_value' if 'biomass_value' in df.columns else 'biomass'\n",
        "    \n",
        "    # Multiple outlier detection methods\n",
        "    methods = {}\n",
        "    \n",
        "    # 1. IQR method\n",
        "    Q1 = df[biomass_col].quantile(0.25)\n",
        "    Q3 = df[biomass_col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    iqr_outliers = df[(df[biomass_col] < lower_bound) | (df[biomass_col] > upper_bound)]\n",
        "    methods['IQR'] = iqr_outliers\n",
        "    \n",
        "    # 2. Z-score method\n",
        "    z_scores = np.abs(stats.zscore(df[biomass_col]))\n",
        "    z_outliers = df[z_scores > 3]\n",
        "    methods['Z-Score'] = z_outliers\n",
        "    \n",
        "    # 3. Percentile method\n",
        "    lower_percentile = df[biomass_col].quantile(0.01)\n",
        "    upper_percentile = df[biomass_col].quantile(0.99)\n",
        "    percentile_outliers = df[(df[biomass_col] < lower_percentile) | (df[biomass_col] > upper_percentile)]\n",
        "    methods['Percentile'] = percentile_outliers\n",
        "    \n",
        "    # Create visualization\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        subplot_titles=(\n",
        "            'Biomass Distribution with Outliers',\n",
        "            'Outlier Detection Methods Comparison',\n",
        "            'Spatial Distribution of Outliers',\n",
        "            'Carbon vs Biomass Anomalies'\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # 1. Biomass distribution with outliers highlighted\n",
        "    normal_data = df[~df.index.isin(iqr_outliers.index)]\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=normal_data[biomass_col], name='Normal', marker_color='lightblue'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Histogram(x=iqr_outliers[biomass_col], name='Outliers', marker_color='red'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # 2. Method comparison\n",
        "    method_counts = [len(methods[method]) for method in methods]\n",
        "    fig.add_trace(\n",
        "        go.Bar(x=list(methods.keys()), y=method_counts, marker_color='orange'),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # 3. Spatial outliers\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=normal_data['longitude'], y=normal_data['latitude'],\n",
        "                 mode='markers', name='Normal', marker=dict(color='blue', size=6)),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=iqr_outliers['longitude'], y=iqr_outliers['latitude'],\n",
        "                 mode='markers', name='Outliers', marker=dict(color='red', size=10)),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    # 4. Carbon vs Biomass anomalies\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=normal_data[biomass_col], y=normal_data['carbon_stock'],\n",
        "                 mode='markers', name='Normal', marker=dict(color='green')),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=iqr_outliers[biomass_col], y=iqr_outliers['carbon_stock'],\n",
        "                 mode='markers', name='Outliers', marker=dict(color='red', size=8)),\n",
        "        row=2, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title_text=\"Comprehensive Anomaly Detection\",\n",
        "        height=700\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Print anomaly insights\n",
        "    print(\"\\nüö® Anomaly Detection Results:\")\n",
        "    print(f\"Total data points: {len(df)}\")\n",
        "    for method, outliers in methods.items():\n",
        "        print(f\"{method} method detected {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    # Common outliers across methods\n",
        "    common_outliers = set()\n",
        "    for outliers in methods.values():\n",
        "        common_outliers.update(outliers.index)\n",
        "    \n",
        "    print(f\"\\nTotal unique outliers detected: {len(common_outliers)} ({len(common_outliers)/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    return methods, common_outliers\n",
        "\n",
        "# Detect anomalies in both datasets\n",
        "print(\"=\"*60)\n",
        "print(\"ANOMALY DETECTION - CSV DATA\")\n",
        "csv_anomalies, csv_common = detect_anomalies(biomass_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANOMALY DETECTION - JSON DATA\")\n",
        "json_anomalies, json_common = detect_anomalies(json_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Key Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_eda_summary(biomass_df, json_df, csv_common, json_common):\n",
        "    \"\"\"Generate comprehensive EDA summary report.\"\"\"\n",
        "    \n",
        "    biomass_col_csv = 'biomass_value' if 'biomass_value' in biomass_df.columns else 'biomass'\n",
        "    biomass_col_json = 'biomass_value' if 'biomass_value' in json_df.columns else 'biomass'\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(\"üìä EXPLORATORY DATA ANALYSIS - COMPREHENSIVE SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(\"\\n1. DATASET OVERVIEW:\")\n",
        "    print(f\"   CSV Data: {biomass_df.shape[0]} samples, {biomass_df.shape[1]} features\")\n",
        "    print(f\"   JSON Data: {json_df.shape[0]} samples, {json_df.shape[1]} features\")\n",
        "    \n",
        "    print(\"\\n2. SPATIAL COVERAGE:\")\n",
        "    print(f\"   CSV - Lat: {biomass_df['latitude'].min():.4f} to {biomass_df['latitude'].max():.4f}\")\n",
        "    print(f\"   CSV - Lon: {biomass_df['longitude'].min():.4f} to {biomass_df['longitude'].max():.4f}\")\n",
        "    print(f\"   JSON - Lat: {json_df['latitude'].min():.4f} to {json_df['latitude'].max():.4f}\")\n",
        "    print(f\"   JSON - Lon: {json_df['longitude'].min():.4f} to {json_df['longitude'].max():.4f}\")\n",
        "    \n",
        "    print(\"\\n3. BIOMASS DISTRIBUTION:\")\n",
        "    print(f\"   CSV - Mean: {biomass_df[biomass_col_csv].mean():.3f} ¬± {biomass_df[biomass_col_csv].std():.3f}\")\n",
        "    print(f\"   JSON - Mean: {json_df[biomass_col_json].mean():.3f} ¬± {json_df[biomass_col_json].std():.3f}\")\n",
        "    print(f\"   Overall Carbon Stock: {biomass_df['carbon_stock'].sum() + json_df['carbon_stock'].sum():.2f} units\")\n",
        "    \n",
        "    print(\"\\n4. DATA QUALITY:\")\n",
        "    print(f\"   CSV Outliers: {len(csv_common)} ({len(csv_common)/len(biomass_df)*100:.1f}%)\")\n",
        "    print(f\"   JSON Outliers: {len(json_common)} ({len(json_common)/len(json_df)*100:.1f}%)\")\n",
        "    \n",
        "    # Check for spatial clustering\n",
        "    print(\"\\n5. SPATIAL PATTERNS:\")\n",
        "    csv_lat_range = biomass_df['latitude'].max() - biomass_df['latitude'].min()\n",
        "    csv_lon_range = biomass_df['longitude'].max() - biomass_df['longitude'].min()\n",
        "    print(f\"   CSV Spatial Coverage: {csv_lat_range:.4f}¬∞ √ó {csv_lon_range:.4f}¬∞\")\n",
        "    \n",
        "    # Correlation insights\n",
        "    print(\"\\n6. KEY RELATIONSHIPS:\")\n",
        "    if 'latitude' in biomass_df.columns and biomass_col_csv in biomass_df.columns:\n",
        "        lat_corr = biomass_df['latitude'].corr(biomass_df[biomass_col_csv])\n",
        "        lon_corr = biomass_df['longitude'].corr(biomass_df[biomass_col_csv])\n",
        "        print(f\"   Latitude-Biomass correlation: {lat_corr:.3f}\")\n",
        "        print(f\"   Longitude-Biomass correlation: {lon_corr:.3f}\")\n",
        "    \n",
        "    print(\"\\n7. RECOMMENDATIONS:\")\n",
        "    if len(csv_common) > 0:\n",
        "        print(\"   ‚ö†Ô∏è  Investigate outliers for data quality issues\")\n",
        "    if biomass_df[biomass_col_csv].std() > 1.5:\n",
        "        print(\"   üìà High variability detected - consider stratification\")\n",
        "    if abs(lat_corr) > 0.3 or abs(lon_corr) > 0.3:\n",
        "        print(\"   üåç Strong spatial patterns detected - include spatial features in models\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ EDA COMPLETED SUCCESSFULLY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "# Generate final summary\n",
        "generate_eda_summary(biomass_df, json_df, csv_common, json_common)\n",
        "\n",
        "# Save processed data with insights\n",
        "biomass_df.to_csv('outputs/biomass_data_with_insights.csv', index=False)\n",
        "json_df.to_csv('outputs/json_data_with_insights.csv', index=False)\n",
        "print(\"\\nüíæ Data with insights saved to 'outputs/' directory\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
